{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 建立在NumPy、SciPy和matplotlib等科学计算库的基础上，用于机器学习的Python开源库\n",
    "\n",
    "### 基础用法包括：\n",
    "* 数据预处理：探索数据清洗、缩放和编码分类变量等工具。\n",
    "\n",
    "* 训练集和测试集划分：使用Scikit-Learn的train_test_split函数将数据集划分为训练集和测试集。\n",
    "\n",
    "* 模型训练：应用不同的机器学习算法，如线性回归、逻辑回归、决策树和随机森林，对数据集进行训练。\n",
    "\n",
    "* 模型评估：使用准确率、精确率、召回率和F1分数等评估指标评估模型性能。\n",
    "\n",
    "#### Scikit-Learn中默认携带了Iris（鸢尾花数据集）breast-cancer(乳腺癌数据集)，我们可以借助这两个数据集来进行sklearn的入门学习。本文使用Iris进行演示。\n",
    "\n",
    "### 数据预处理\n",
    "#### 读取数据集\n",
    "datasets\n",
    "\n",
    "### 默认数据格式\n",
    "Sklearn 里模型能直接使用的数据有两种形式：\n",
    "\n",
    "Numpy二维数组 (ndarray)的稠密数据 (dense data)，通常都是这种格式。\n",
    "SciPy矩阵 (scipy.sparse.matrix)的稀疏数据 (sparse data)，比如文本分析每个单词(字典有100000个词)做独热编码得到矩阵有很多0，这时用ndarray就不合适了，太耗内存。\n",
    "\n",
    "### 划分测试集\n",
    "train_test_split(*arrays,test_size=None,train_size=None,random_state=None,shuffle=True,stratify=None):\n",
    "* shuffle 是否在划分前打乱顺序\n",
    "* stratify 当设置了 stratify 参数，数据集将以分层的方式被分割，以确保训练集和测试集中各类别（标签）的样本比例与整个原始数据集中的比例一致。\n",
    "\n",
    "### 数据缩放\n",
    "特征缩放是指将数据集中的特征值进行标准化或归一化的过程。\n",
    "特征缩放的目的是为了消除特征之间的量纲差异，使得不同特征之间的比较更加合理和准确。\n",
    "\n",
    "### 线性模型\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "### SVM\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#### 使用SVM核函数来处理非线性问题\n",
    "在支持向量机（SVM）中，核技巧（kernel trick）是一种强大的方法，用于在高维空间中找到分离超平面，特别是当数据在原始特征空间中是非线性可分的。核技巧的核心思想是通过一个非线性映射将原始数据映射到一个更高维的空间，在这个新空间中，原本非线性可分的数据可能变得线性可分。\n",
    "\n",
    "### 决策树\n",
    "最大化信息增益 - 获取最大收益\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "### 集成学习\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "### KNN\n",
    "K最近邻（K-Nearest Neighbors，简称KNN）算法主要被用作有监督学习中的分类和回归算法，而不是聚类算法。\n",
    "\n",
    "### SGDClassifier\n",
    "是一个使用随机梯度下降（Stochastic Gradient Descent，SGD）进行优化的通用线性分类器。\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "ppn = SGDClassifier(loss='perceptron')\n",
    "lr = SGDClassifier(loss='log')\n",
    "svm = SGDClassifier(loss='hinge')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 特征抽取"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "v = DictVectorizer(sparse=False)\n",
    "D = [{'foo': 1, 'bar': 2}, {'foo': 3, 'baz': 1}]\n",
    "X = v.fit_transform(D)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 特征选择"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n",
      "(1797, 2)\n",
      "[[ 5. 11.]\n",
      " [ 0.  1.]\n",
      " [ 1. 16.]\n",
      " ...\n",
      " [ 0. 16.]\n",
      " [ 0.  0.]\n",
      " [ 0. 16.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "X, y = load_digits(return_X_y=True)\n",
    "print(X.shape)\n",
    "## 特征选择\n",
    "X_new = SelectKBest(chi2, k=2).fit_transform(X, y)\n",
    "print(X_new.shape)\n",
    "# SelectKBest：这个方法用于选择最好的 K 个特征。它根据统计测试选择特征，以保留最相关的特征。\n",
    "# chi2：卡方检验，用于分类任务。它评估每个特征和目标变量之间的独立性。卡方值越高，表明特征和目标变量的相关性越强。\n",
    "# k=20：指定选择的特征数量。这意味着从所有可用特征中选择 20 个最重要的特征。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 拟合与预测\n",
    "#### 拟合训练集\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "#### 预测\n",
    "y_pred=knn.predict(X_test)\n",
    "\n",
    "### 模型评估\n",
    "#### 求精度\n",
    "knn.score(X_test,y_test)\n",
    "#### 绘制混淆矩阵\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#### 绘制ROC曲线\n",
    "from sklearn.metrics import roc_curve,roc_auc_score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}