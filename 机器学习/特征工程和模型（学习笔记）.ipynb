{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 特征工程\n",
    "* 地位：特征工程是机器学习中非常关键的一个步骤。\n",
    "* 它涉及到从原始数据中选择、修改和创建对于机器学习算法有效的特征（即输入变量），以改进模型的性能和预测能力。\n",
    "### 步骤\n",
    "* 特征选择：\n",
    "    * 地位：这是选择最有影响力或最相关特征的过程。\n",
    "    * 理论依据：不是所有特征都对预测结果有帮助，有些可能是冗余的。\n",
    "    * 作用：有效的特征选择可以减少模型的复杂性和过拟合的风险。\n",
    "* 特征转换：\n",
    "    * 方法：这涉及到改变特征的格式或值，以使其更适合机器学习模型。\n",
    "    * 例如，通过对数转换或平方根转换来处理偏态分布的特征。\n",
    "* 特征缩放：\n",
    "    * 理论依据：在许多机器学习算法中，特别是那些基于距离的算法（如K-最近邻或支持向量机），__确保所有特征在相似的尺度上__是很重要的。\n",
    "    * 常见的技术包括归一化（将数据缩放到0和1之间）和标准化（将数据转换为均值为0，标准差为1的分布）。\n",
    "* 特征构建：\n",
    "    * 方法：这是创建新特征的过程，通常是通过已有特征的组合或变换。这可以帮助增强模型的预测能力。\n",
    "\n",
    "## 模型\n",
    "### 定义：模型是指通过算法从数据中学习得到的系统，用于进行预测或决策。\n",
    ">模型是数据和输出之间的数学映射关系。模型的类型和复杂性取决于具体的任务和使用的算法。\n",
    "### 模型分类：\n",
    "* 按学习方式分类：\n",
    "    * 监督学习：模型从标记的训练数据中学习，如分类和回归。\n",
    "    * 无监督学习：模型从未标记的数据中学习，如聚类和降维。\n",
    "    * 半监督学习：结合了监督学习和无监督学习的特点。它使用少量的标记数据和大量的未标记数据。\n",
    "    * 自监督学习：它介于监督学习和无监督学习之间。这种方法的核心思想是利用数据本身生成伪标签（pseudo-labels）或任务，从而训练模型。\n",
    "    * 强化学习：模型通过与环境的互动来学习，目标是最大化累积奖励。\n",
    "* 算法类型分类：\n",
    "  * 线性模型\n",
    "    * 线性回归：用于回归问题，预测连续值。\n",
    "    * 逻辑回归：用于分类问题，尤其是二分类。\n",
    "  * 基于树的模型\n",
    "    * 决策树：适用于分类和回归问题，通过构建决策树来做出预测。\n",
    "    * 随机森林：是决策树的集成方法，用多个树进行预测。\n",
    "    * 梯度提升决策树（GBDT）：通过顺序建立决策树，每棵树修正前一棵树的错误。\n",
    "  * 神经网络\n",
    "    * 多层感知器（MLP）：基础的神经网络结构，用于分类和回归。\n",
    "    * 卷积神经网络（CNN）：主要用于图像处理。\n",
    "    * 循环神经网络（RNN）：适用于序列数据，如时间序列分析和自然语言处理。\n",
    "    * 变分自编码器（VAE）：用于生成模型，特别在图像生成和重构方面表现突出。\n",
    "    * 生成对抗网络（GAN）：同样用于生成模型，尤其在生成逼真图像和艺术创作方面有重要应用。\n",
    "    * Transformer模型：在自然语言处理领域取得了革命性进展，如BERT、GPT系列。这些模型通过自注意力机制有效处理序列数据。\n",
    "    * 图神经网络（GNN）：用于处理图结构数据，如社交网络分析、蛋白质结构预测等。\n",
    "  * 支持向量机（SVM）：适用于分类和回归问题，特别是在高维空间中表现出色。\n",
    "  * K-最近邻（K-NN）：用于分类和回归，基于距离的简单算法。\n",
    "  * 贝叶斯方法：\n",
    "    * 朴素贝叶斯：基于贝叶斯定理，适用于分类，特别是文本分类。\n",
    "    * 高斯过程：用于回归问题，特别是在不确定性建模方面。\n",
    "  * 概率图模型\n",
    "  * 集成方法\n",
    "    * Bagging：如随机森林。\n",
    "    * Boosting：如AdaBoost、梯度提升。\n",
    "    * Stacking：将不同模型的预测结果作为输入，再训练一个新的模型来做最终的预测。\n",
    "  * 聚类算法\n",
    "    * K-均值（K-Means）：用于数据的聚类分析。\n",
    "    * 层次聚类：基于层次的聚类方法。\n",
    "    * DBSCAN：是一种基于密度的空间聚类算法。与基于距离或基于划分的聚类算法不同，DBSCAN关注点的邻域密度，并可以识别任意形状的簇。这种算法特别适用于数据集中存在大量噪声和异常点的情况。\n",
    "  * 强化学习\n",
    "    * 如Q-learning、SARSA、深度Q网络（DQN）。\n",
    "\n",
    "## 4. 模型训练\n",
    "模型训练是指使用数据和算法来训练机器学习模型。这通常涉及以下步骤：\n",
    "* 选择合适的算法。\n",
    "* 准备数据：包括数据清洗、特征工程等。\n",
    "* 训练模型：使用训练数据来训练模型。\n",
    "* 验证模型：使用验证数据集来测试模型的性能。\n",
    "\n",
    "### 验证集\n",
    ">验证集用于模型的选择和调优。\n",
    ">\n",
    "> 测试集用于提供一个最终的、未经污染的性能评估，以判断模型的泛化能力。\n",
    "\n",
    "* 目的：验证集主要用于模型的调优和验证。它用来调整模型的超参数，如学习率、层数、神经元数量等，并且用来评估模型在训练过程中的性能。\n",
    "* 使用时机：在模型训练过程中使用。通过在验证集上评估模型性能，我们可以了解模型是否过拟合或欠拟合，并据此调整模型配置。\n",
    "* 重复使用：验证集可以在模型训练过程中被多次使用，因为主要目的是模型的调整和优化。\n",
    "#### 模型验证的常见策略\n",
    "* 留出验证：直接从训练集中分离一部分数据作为验证集。\n",
    "* 交叉验证：将数据分成几个部分，轮流使用其中一部分作为验证数据，其余作为训练数据。\n",
    "* 自助法：通过有放回的抽样创建多个训练集，剩余未被抽中的数据作为验证集。\n",
    "## 模型调优\n",
    "模型调优指的是改善模型性能的过程。主要包括：\n",
    "* 调整参数：调整算法的超参数来提高性能。\n",
    "* 特征选择：选择最有效的特征。\n",
    "* 集成方法：如Bagging、Boosting，通过组合多个模型来提高性能。\n",
    "* 正则化：减少过拟合，增强模型的泛化能力。\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}